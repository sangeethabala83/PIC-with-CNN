{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN0GOWqxmDIsKZ8yFumWoky"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0kQ8ZA85VtRx","executionInfo":{"status":"ok","timestamp":1747648352496,"user_tz":-330,"elapsed":10455,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","\n","# --- Custom Trainable PI Layer ---\n","class TrainablePILayer(layers.Layer):\n","    def __init__(self, target_intensity=0.5, max_iter=1):\n","        super(TrainablePILayer, self).__init__()\n","        self.target_intensity = target_intensity\n","        self.max_iter = max_iter\n","\n","    def build(self, input_shape):\n","        self.Kp = self.add_weight(name='Kp', shape=(), initializer=tf.constant_initializer(0.5), trainable=True)\n","        self.Ki = self.add_weight(name='Ki', shape=(), initializer=tf.constant_initializer(0.1), trainable=True)\n","\n","    def call(self, inputs):\n","        x = tf.identity(inputs)\n","        integral_error = tf.constant(0.0, dtype=inputs.dtype)\n","\n","        for _ in range(self.max_iter):\n","            current_mean = tf.reduce_mean(x)\n","            error = self.target_intensity - current_mean\n","            integral_error += error\n","            adjustment = self.Kp * error + self.Ki * integral_error\n","            x = x + adjustment\n","            x = tf.clip_by_value(x, 0.0, 1.0)\n","\n","        return x\n","\n","# --- CNN Model with PI Layer ---\n","class CNNWithPIConvOutput(Model):\n","    def __init__(self):\n","        super(CNNWithPIConvOutput, self).__init__()\n","        self.pi = TrainablePILayer()\n","        self.conv1 = layers.Conv2D(32, 3, padding='same', activation='relu')\n","        self.bn1 = layers.BatchNormalization()\n","        self.pool1 = layers.MaxPooling2D(2)\n","\n","\n","\n","        self.conv2 = layers.Conv2D(64, 3, padding='same', activation='relu')\n","        self.bn2 = layers.BatchNormalization()\n","        self.pool2 = layers.MaxPooling2D(2)\n","\n","        self.conv3 = layers.Conv2D(128, 3, padding='same', activation='relu')\n","        self.bn3 = layers.BatchNormalization()\n","        self.pool3 = layers.MaxPooling2D(2)\n","\n","        self.out_conv = layers.Conv2D(1, kernel_size=1, activation='sigmoid')\n","        self.global_avg_pool = layers.GlobalAveragePooling2D()\n","\n","    def call(self, inputs, training=False, return_features=False):\n","        feat_before = x\n","        x = self.pi(x)\n","        feat_after = x\n","        x = self.conv1(inputs)\n","        x = self.bn1(x, training=training)\n","        x = self.pool1(x)\n","\n","\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x, training=training)\n","        x = self.pool2(x)\n","\n","        x = self.conv3(x)\n","        x = self.bn3(x, training=training)\n","        x = self.pool3(x)\n","\n","        x = self.out_conv(x)\n","        x = self.global_avg_pool(x)\n","\n","        if return_features:\n","            return x, feat_before, feat_after\n","        return x"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.models import Sequential  # Assuming TensorFlow 2.0+\n","import keras\n","!pip install keras\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","!pip install keras-preprocessing\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.regularizers import l1, l2\n","import PIL.Image\n","from tensorflow.keras.preprocessing.image import load_img"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O99mJ5SSXCyv","executionInfo":{"status":"ok","timestamp":1747648362784,"user_tz":-330,"elapsed":5655,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"72a84b58-c2c5-4219-dc9e-0540ff0ad2bb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: keras-preprocessing in /usr/local/lib/python3.11/dist-packages (1.1.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-preprocessing) (2.0.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras-preprocessing) (1.17.0)\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# Specify the path to your zip file\n","zip_file_path = '/content/42.zip'\n","\n","# Specify the directory where you want to extract the files\n","extract_to_dir = '/content/29unzip'\n","\n","# Create the extraction directory if it doesn't exist\n","os.makedirs(extract_to_dir, exist_ok=True)\n","\n","# Open the zip file and extract its contents\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_to_dir)\n","\n","# Print a message indicating the extraction directory\n","print(f\"Files extracted to {extract_to_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGpHScOWXGze","executionInfo":{"status":"ok","timestamp":1747648482146,"user_tz":-330,"elapsed":636,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"d9a94951-399d-4f67-f64e-127d0729fe04"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Files extracted to /content/29unzip\n"]}]},{"cell_type":"code","source":["!pip install tensorflow keras numpy matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRXMNKclXIP2","executionInfo":{"status":"ok","timestamp":1747648391323,"user_tz":-330,"elapsed":3099,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"2d78337f-61cd-4fc2-8814-bf3b35c81857"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"]}]},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img"],"metadata":{"id":"lJbqSD0ZXL3u","executionInfo":{"status":"ok","timestamp":1747648403566,"user_tz":-330,"elapsed":22,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"],"metadata":{"id":"pmRWRWRLXQh-","executionInfo":{"status":"ok","timestamp":1747648405698,"user_tz":-330,"elapsed":25,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["input_folder = '/content/29unzip/1111/Bengin cases'\n","output_folder = '/content/29unzip/1111/Bengin cases'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","target_total = 465\n","current_count = len(os.listdir(input_folder))\n","images_needed = target_total - current_count\n","\n","image_files = os.listdir(input_folder)\n","generated = 0\n","\n","while generated < images_needed:\n","    for img_file in image_files:\n","        img_path = os.path.join(input_folder, img_file)\n","        img = load_img(img_path)\n","        x = img_to_array(img)\n","        x = x.reshape((1,) + x.shape)\n","\n","        # Generate one augmented image per iteration\n","        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_folder,\n","                                  save_prefix='aug', save_format='jpeg'):\n","            generated += 1\n","            if generated >= images_needed:\n","                break\n","    if generated >= images_needed:\n","        break\n","\n","print(f\"Generated {generated} augmented images.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh6m49mxXUPO","executionInfo":{"status":"ok","timestamp":1747648499896,"user_tz":-330,"elapsed":15,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"adb4a44a-f532-4dc9-b2a3-68dac0d84277"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated 0 augmented images.\n"]}]},{"cell_type":"code","source":["#count number of images and classes Benign=0 maligant=1\n","ROOT_DIR=\"/content/29unzip/1111\"\n","number_of_images={}\n","for dir in os.listdir(ROOT_DIR):\n","       number_of_images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))\n","       number_of_images.items()"],"metadata":{"id":"5bZSHeFhXYQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","import math\n","\n","ROOT_DIR = '/content/29unzip/1111'  # replace with your dataset root\n","random.seed(42)  # for reproducibility\n","\n","# Count the number of images in each class\n","number_of_images = {}\n","for dir_name in os.listdir(ROOT_DIR):\n","    dir_path = os.path.join(ROOT_DIR, dir_name)\n","    if os.path.isdir(dir_path):\n","        number_of_images[dir_name] = len(os.listdir(dir_path))\n","\n","# Create train, validation, and test folders if not exist\n","for split in ['train111x', 'validation111x', 'test111x']:\n","    if not os.path.exists(split):\n","        os.mkdir(split)\n","        for class_name in os.listdir(ROOT_DIR):\n","            class_path = os.path.join(ROOT_DIR, class_name)\n","            if os.path.isdir(class_path):\n","                os.makedirs(os.path.join(split, class_name), exist_ok=True)\n","\n","# Split the dataset\n","for class_name in os.listdir(ROOT_DIR):\n","    class_path = os.path.join(ROOT_DIR, class_name)\n","    if not os.path.isdir(class_path):\n","        continue\n","\n","    all_images = os.listdir(class_path)\n","    random.shuffle(all_images)  # shuffle once\n","\n","    total_images = len(all_images)\n","    train_size = int(0.8 * total_images)\n","    val_size = int(0.1 * total_images)\n","    test_size = total_images - train_size - val_size  # remainder to test\n","\n","    train_images = all_images[:train_size]\n","    val_images = all_images[train_size:train_size + val_size]\n","    test_images = all_images[train_size + val_size:]\n","\n","    # Move or copy files\n","    for img in train_images:\n","        shutil.copy(os.path.join(class_path, img), os.path.join('train111x', class_name, img))\n","\n","    for img in val_images:\n","        shutil.copy(os.path.join(class_path, img), os.path.join('validation111x', class_name, img))\n","\n","    for img in test_images:\n","        shutil.copy(os.path.join(class_path, img), os.path.join('test111x', class_name, img))\n","\n","print(\"Dataset splitting completed successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJFey4V7XqIm","executionInfo":{"status":"ok","timestamp":1747648680491,"user_tz":-330,"elapsed":325,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"d9ebf755-7390-4198-ba7f-754a73452995"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset splitting completed successfully.\n"]}]},{"cell_type":"code","source":["# Count the number of images in the validation folder\n","number_of_images_val = {}\n","for dir in os.listdir(\"./validation111x\"):\n","    number_of_images_val[dir] = len(os.listdir(os.path.join(\"./validation111x\", dir)))\n","\n","number_of_images_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9aNl5ufXucW","executionInfo":{"status":"ok","timestamp":1747648687219,"user_tz":-330,"elapsed":49,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"02dc1fe4-5dc2-4eab-cf3e-9cfd333d939f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Malignant cases': 56, 'Bengin cases': 57}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Count the number of images in the training folder\n","number_of_images_train = {}\n","for dir in os.listdir(\"./train111x\"):\n","    number_of_images_train[dir] = len(os.listdir(os.path.join(\"./train111x\", dir)))\n","\n","number_of_images_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ERm12Z5kXx2O","executionInfo":{"status":"ok","timestamp":1747648690419,"user_tz":-330,"elapsed":13,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"2414a36c-9d91-49c4-86d6-3f323812c79f"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Malignant cases': 448, 'Bengin cases': 460}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Count the number of images in the test folder\n","number_of_images_test = {}\n","for dir in os.listdir(\"./test111x\"):\n","    number_of_images_test[dir] = len(os.listdir(os.path.join(\"./test111x\", dir)))\n","\n","number_of_images_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6k7zKD5kX0q_","executionInfo":{"status":"ok","timestamp":1747648692727,"user_tz":-330,"elapsed":29,"user":{"displayName":"sangeetha bala","userId":"10663675971153495354"}},"outputId":"acb9ca77-386d-49b0-8a43-92ed04efeaf9"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Malignant cases': 57, 'Bengin cases': 58}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","\n","\n","# --- Custom Trainable PI Layer ---\n","class TrainablePILayer(layers.Layer):\n","    def __init__(self, target_intensity=0.5, max_iter=1):\n","        super(TrainablePILayer, self).__init__()\n","        self.target_intensity = target_intensity\n","        self.max_iter = max_iter\n","\n","    def build(self, input_shape):\n","        self.Kp = self.add_weight(name='Kp', shape=(), initializer=tf.constant_initializer(0.5), trainable=True)\n","        self.Ki = self.add_weight(name='Ki', shape=(), initializer=tf.constant_initializer(0.1), trainable=True)\n","\n","    def call(self, inputs):\n","        x = tf.identity(inputs)\n","        integral_error = tf.constant(0.0, dtype=inputs.dtype)\n","\n","        for _ in range(self.max_iter):\n","            current_mean = tf.reduce_mean(x)\n","            error = self.target_intensity - current_mean\n","            integral_error += error\n","            adjustment = self.Kp * error + self.Ki * integral_error\n","            x = x + adjustment\n","            x = tf.clip_by_value(x, 0.0, 1.0)\n","\n","        return x\n","\n","# --- CNN Model with PI Layer before first conv ---\n","class CNNWithPIConvOutput(Model):\n","    def __init__(self):\n","        super(CNNWithPIConvOutput, self).__init__()\n","        self.pi = TrainablePILayer()\n","\n","        self.conv1 = layers.Conv2D(32, 3, padding='same', activation='relu')\n","        self.bn1 = layers.BatchNormalization()\n","        self.pool1 = layers.MaxPooling2D(2)\n","\n","        self.conv2 = layers.Conv2D(64, 3, padding='same', activation='relu')\n","        self.bn2 = layers.BatchNormalization()\n","        self.pool2 = layers.MaxPooling2D(2)\n","\n","        self.conv3 = layers.Conv2D(128, 3, padding='same', activation='relu')\n","        self.bn3 = layers.BatchNormalization()\n","        self.pool3 = layers.MaxPooling2D(2)\n","\n","        self.out_conv = layers.Conv2D(1, kernel_size=1, activation='sigmoid')\n","        self.global_avg_pool = layers.GlobalAveragePooling2D()\n","\n","    def call(self, inputs, training=False, return_features=False):\n","        x = self.pi(inputs)\n","        feat_after_pi = x  # Feature right after PI layer\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x, training=training)\n","        x = self.pool1(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x, training=training)\n","        x = self.pool2(x)\n","\n","        x = self.conv3(x)\n","        x = self.bn3(x, training=training)\n","        x = self.pool3(x)\n","\n","        x = self.out_conv(x)\n","        x = self.global_avg_pool(x)\n","\n","        if return_features:\n","            return x, feat_after_pi\n","        return x\n","\n","\n","# --- Data paths and preprocessing ---\n","train_dir = '/content/train111x'\n","val_dir = '/content/validation111x'\n","IMG_WIDTH, IMG_HEIGHT = 224, 224\n","BATCH_SIZE = 64\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_data = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(IMG_WIDTH, IMG_HEIGHT),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary'\n",")\n","\n","val_data = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=(IMG_WIDTH, IMG_HEIGHT),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary'\n",")\n","\n","# --- Model Training ---\n","model = CNNWithPIConvOutput()\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n","lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",")\n","\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(\n","    train_data,\n","    epochs=50,\n","    validation_data=val_data,\n","    callbacks=[lr_scheduler]\n",")\n","\n","# --- Plot Training Curves ---\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(len(acc))\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","plt.grid(True)\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVl-4p2MX6C2","outputId":"79f47068-9f82-4ea3-d139-b3661723c6f0"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Found 908 images belonging to 2 classes.\n","Found 113 images belonging to 2 classes.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 12s/step - accuracy: 0.8750 - loss: 0.4807 - val_accuracy: 0.4956 - val_loss: 0.7005 - learning_rate: 1.0000e-04\n","Epoch 2/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12s/step - accuracy: 0.9073 - loss: 0.3344 - val_accuracy: 0.4956 - val_loss: 0.7187 - learning_rate: 1.0000e-04\n","Epoch 3/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12s/step - accuracy: 0.9030 - loss: 0.2988 - val_accuracy: 0.4956 - val_loss: 0.7541 - learning_rate: 1.0000e-04\n","Epoch 4/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13s/step - accuracy: 0.9197 - loss: 0.2529 - val_accuracy: 0.4956 - val_loss: 0.8271 - learning_rate: 1.0000e-04\n","Epoch 5/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 12s/step - accuracy: 0.9218 - loss: 0.2298 - val_accuracy: 0.4956 - val_loss: 0.9378 - learning_rate: 1.0000e-04\n","Epoch 6/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.9297 - loss: 0.2160 \n","Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12s/step - accuracy: 0.9286 - loss: 0.2168 - val_accuracy: 0.4956 - val_loss: 1.0987 - learning_rate: 1.0000e-04\n","Epoch 7/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 13s/step - accuracy: 0.9013 - loss: 0.2272 - val_accuracy: 0.4956 - val_loss: 1.2626 - learning_rate: 5.0000e-05\n","Epoch 8/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12s/step - accuracy: 0.9323 - loss: 0.1958 - val_accuracy: 0.4956 - val_loss: 1.4183 - learning_rate: 5.0000e-05\n","Epoch 9/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12s/step - accuracy: 0.9173 - loss: 0.2004 - val_accuracy: 0.4956 - val_loss: 1.5899 - learning_rate: 5.0000e-05\n","Epoch 10/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 12s/step - accuracy: 0.9154 - loss: 0.2012 - val_accuracy: 0.4956 - val_loss: 1.7149 - learning_rate: 5.0000e-05\n","Epoch 11/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.9062 - loss: 0.2110 \n","Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 13s/step - accuracy: 0.9067 - loss: 0.2107 - val_accuracy: 0.4956 - val_loss: 1.8234 - learning_rate: 5.0000e-05\n","Epoch 12/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12s/step - accuracy: 0.9185 - loss: 0.1940 - val_accuracy: 0.4956 - val_loss: 1.8569 - learning_rate: 2.5000e-05\n","Epoch 13/50\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12s/step - accuracy: 0.9174 - loss: 0.1873 - val_accuracy: 0.4956 - val_loss: 1.8723 - learning_rate: 2.5000e-05\n","Epoch 14/50\n","\u001b[1m 2/15\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 12s/step - accuracy: 0.9336 - loss: 0.1818"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import (\n","    confusion_matrix, ConfusionMatrixDisplay,\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    roc_auc_score, roc_curve\n",")\n","\n","# --- Custom Trainable PI Layer ---\n","class TrainablePILayer(layers.Layer):\n","    def __init__(self, target_intensity=0.5, max_iter=1):\n","        super(TrainablePILayer, self).__init__()\n","        self.target_intensity = target_intensity\n","        self.max_iter = max_iter\n","\n","    def build(self, input_shape):\n","        self.Kp = self.add_weight(name='Kp', shape=(), initializer=tf.constant_initializer(0.5), trainable=True)\n","        self.Ki = self.add_weight(name='Ki', shape=(), initializer=tf.constant_initializer(0.1), trainable=True)\n","\n","    def call(self, inputs):\n","        x = tf.identity(inputs)\n","        integral_error = tf.constant(0.0, dtype=inputs.dtype)\n","\n","        for _ in range(self.max_iter):\n","            current_mean = tf.reduce_mean(x)\n","            error = self.target_intensity - current_mean\n","            integral_error += error\n","            adjustment = self.Kp * error + self.Ki * integral_error\n","            x = x + adjustment\n","            x = tf.clip_by_value(x, 0.0, 1.0)\n","\n","        return x\n","\n","# --- CNN Model with PI Layer before first conv ---\n","class CNNWithPIConvOutput(Model):\n","    def __init__(self):\n","        super(CNNWithPIConvOutput, self).__init__()\n","        self.pi = TrainablePILayer()\n","\n","        self.conv1 = layers.Conv2D(32, 3, padding='same', activation='relu')\n","        self.bn1 = layers.BatchNormalization()\n","        self.pool1 = layers.MaxPooling2D(2)\n","\n","        self.conv2 = layers.Conv2D(64, 3, padding='same', activation='relu')\n","        self.bn2 = layers.BatchNormalization()\n","        self.pool2 = layers.MaxPooling2D(2)\n","\n","        self.conv3 = layers.Conv2D(128, 3, padding='same', activation='relu')\n","        self.bn3 = layers.BatchNormalization()\n","        self.pool3 = layers.MaxPooling2D(2)\n","\n","        self.out_conv = layers.Conv2D(1, kernel_size=1, activation='sigmoid')\n","        self.global_avg_pool = layers.GlobalAveragePooling2D()\n","\n","    def call(self, inputs, training=False, return_features=False):\n","        x = self.pi(inputs)\n","        feat_after_pi = x  # Feature right after PI layer\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x, training=training)\n","        x = self.pool1(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x, training=training)\n","        x = self.pool2(x)\n","\n","        x = self.conv3(x)\n","        x = self.bn3(x, training=training)\n","        x = self.pool3(x)\n","\n","        x = self.out_conv(x)\n","        x = self.global_avg_pool(x)\n","\n","        if return_features:\n","            return x, feat_after_pi\n","        return x\n","\n","\n","\n","# --- Parameters ---\n","IMG_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","EPOCHS = 50\n","\n","# --- Data Preparation ---\n","train_dir = '/content/train111x'\n","val_dir = '/content/validation111x'\n","test_dir = '/content/test111x'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.3,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    shuffle=True\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary',\n","    shuffle=False\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=IMG_SIZE,\n","    batch_size=32,\n","    class_mode='binary',\n","    shuffle=False\n",")\n","\n","# --- Model Instantiation and Compilation ---\n","model = CNNWithPIConvOutput()\n","model.compile(optimizer=tf.keras.optimizers.Adam(),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","# --- Train the Model (no callbacks) ---\n","history = model.fit(\n","    train_generator,\n","    epochs=EPOCHS,\n","    validation_data=val_generator\n",")\n","\n","# --- Evaluate on Test Data ---\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Accuracy: {test_acc:.4f}\")\n","\n","# --- Predictions ---\n","pred_probs = model.predict(test_generator)\n","pred_classes = (pred_probs > 0.5).astype(int).ravel()\n","true_classes = test_generator.classes\n","class_labels = list(test_generator.class_indices.keys())\n","\n","# --- Confusion Matrix ---\n","cm = confusion_matrix(true_classes, pred_classes)\n","print(\"Confusion Matrix:\\n\", cm)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","disp.plot(cmap=plt.cm.Blues)\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# --- Metrics ---\n","accuracy = accuracy_score(true_classes, pred_classes)\n","precision = precision_score(true_classes, pred_classes, zero_division=0)\n","recall = recall_score(true_classes, pred_classes, zero_division=0)\n","f1 = f1_score(true_classes, pred_classes, zero_division=0)\n","auc = roc_auc_score(true_classes, pred_probs)\n","\n","print(f\"Accuracy:  {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall:    {recall:.4f}\")\n","print(f\"F1 Score:  {f1:.4f}\")\n","print(f\"AUC-ROC:   {auc:.4f}\")\n","\n","# --- ROC Curve ---\n","fpr, tpr, _ = roc_curve(true_classes, pred_probs)\n","plt.figure(figsize=(8,6))\n","plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n","plt.plot([0,1], [0,1], 'k--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc='lower right')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"NLktOhlo3TwA"},"execution_count":null,"outputs":[]}]}